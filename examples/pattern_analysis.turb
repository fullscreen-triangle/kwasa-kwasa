// Example of pattern-based meaning extraction using Turbulance

// Some example text with potentially interesting patterns
var text = "The quick brown fox jumps over the lazy dog. How vexingly quick daft zebras jump!"

// Function to analyze letter frequency
funxn letter_frequency(text):
    var frequencies = {}
    var total = 0
    
    within text as characters:
        given character.is_alpha():
            var char_lower = character.lower()
            
            given char_lower in frequencies:
                frequencies[char_lower] = frequencies[char_lower] + 1
            given otherwise:
                frequencies[char_lower] = 1
                
            total = total + 1
    
    // Convert to percentages
    for each letter in frequencies:
        frequencies[letter] = frequencies[letter] / total
    
    return frequencies

// Calculate Shannon entropy of text
funxn calculate_entropy(text):
    var frequencies = letter_frequency(text)
    var entropy = 0.0
    
    for each letter, freq in frequencies:
        given freq > 0:
            entropy = entropy - freq * log2(freq)
    
    return entropy

// Detect recurring visual patterns
funxn detect_visual_patterns(text, pattern_length=3):
    // Map letters to shape classes
    var shape_classes = {
        'a': 0, 'c': 0, 'e': 0, 'o': 0, 's': 0,  // round shapes
        'i': 1, 'l': 1, 'j': 1, 'f': 1, 't': 1,  // vertical strokes
        'm': 2, 'n': 2, 'h': 2, 'u': 2,          // arch shapes
        'v': 3, 'w': 3, 'x': 3, 'y': 3, 'z': 3,  // angled shapes
        'b': 4, 'd': 4, 'p': 4, 'q': 4, 'g': 4   // circles with stems
    }
    
    var shape_patterns = {}
    
    for i in range(len(text) - pattern_length + 1):
        var current_pattern = []
        var valid_pattern = true
        
        for j in range(pattern_length):
            var char = text[i+j].lower()
            
            given char in shape_classes:
                current_pattern.append(shape_classes[char])
            given otherwise:
                valid_pattern = false
                break
        
        given valid_pattern:
            var pattern_key = tuple(current_pattern)
            
            given pattern_key in shape_patterns:
                shape_patterns[pattern_key].append(text[i:i+pattern_length])
            given otherwise:
                shape_patterns[pattern_key] = [text[i:i+pattern_length]]
    
    // Filter for patterns that occur multiple times
    var recurring_patterns = {}
    
    for each pattern, occurrences in shape_patterns:
        given len(occurrences) > 1:
            recurring_patterns[pattern] = occurrences
    
    return recurring_patterns

// Generate a visual rhythm analysis
funxn visual_rhythm(text):
    var weights = []
    var current_weight = 0.0
    
    within text as characters:
        var weight = 0.4  // default
        
        given character in "il.,':;":
            weight = 0.2  // thin
        given character in "acemnorsuvwxz":
            weight = 0.5  // medium
        given character in "bdfhkt":
            weight = 0.7  // tall
        given character in "gjpqy":
            weight = 0.8  // descenders
        given character == " ":
            weight = 0.1  // space
            
        // Moving average
        current_weight = 0.8 * current_weight + 0.2 * weight
        weights.append(current_weight)
    
    return weights

// Extract orthographic density map
funxn orthographic_density(text, width=40):
    var height = ceil(len(text) / width)
    var density_map = []
    
    // Create empty map
    for y in range(height):
        var row = []
        for x in range(width):
            row.append(0.0)
        density_map.append(row)
    
    // Fill the map
    for i in range(len(text)):
        var x = i % width
        var y = i // width
        var char = text[i]
        var density = 0.4  // default
        
        given char in "il.,':;":
            density = 0.2  // thin
        given char in "acemnorsuvwxz":
            density = 0.5  // medium
        given char in "bdfhkt":
            density = 0.7  // tall
        given char in "gjpqy":
            density = 0.8  // descenders
        given char in "mwBGOQ":
            density = 0.8  // wide
        given char in "WM%@#":
            density = 0.9  // very heavy
        given char == " ":
            density = 0.1  // space
            
        given y < len(density_map) and x < len(density_map[y]):
            density_map[y][x] = density
    
    return density_map

// Function to find unusual letter combinations
funxn unusual_combinations(text, ngram_size=2):
    var ngrams = {}
    var total_ngrams = 0
    
    // Count n-grams
    for i in range(len(text) - ngram_size + 1):
        var ngram = text[i:i+ngram_size].lower()
        
        // Only consider alphabetic n-grams
        var is_alpha = true
        for each char in ngram:
            given not char.is_alpha():
                is_alpha = false
                break
        
        given is_alpha:
            given ngram in ngrams:
                ngrams[ngram] = ngrams[ngram] + 1
            given otherwise:
                ngrams[ngram] = 1
                
            total_ngrams = total_ngrams + 1
    
    // English letter pair frequencies (approximate)
    var expected_freqs = {
        'th': 0.0356, 'he': 0.0307, 'in': 0.0243, 'er': 0.0205,
        'an': 0.0199, 're': 0.0185, 'on': 0.0176, 'at': 0.0149,
        'en': 0.0145, 'nd': 0.0135, 'ti': 0.0134, 'es': 0.0134,
        'or': 0.0128, 'te': 0.0120, 'of': 0.0115, 'ed': 0.0117,
        'is': 0.0113, 'it': 0.0112, 'al': 0.0109, 'ar': 0.0107,
        'st': 0.0105, 'to': 0.0104, 'nt': 0.0104, 'ng': 0.0095,
        'se': 0.0093, 'ha': 0.0093, 'as': 0.0087, 'ou': 0.0087,
        'io': 0.0083, 'le': 0.0083, 've': 0.0083, 'co': 0.0079,
        'me': 0.0079, 'de': 0.0076, 'hi': 0.0076, 'ri': 0.0073,
        'ro': 0.0073, 'ic': 0.0070, 'ne': 0.0069, 'ea': 0.0069,
        'ra': 0.0069, 'ce': 0.0068, 'li': 0.0062, 'ch': 0.0060,
        'll': 0.0058, 'be': 0.0058, 'ma': 0.0056, 'si': 0.0055
    }
    
    // Find unusual combinations
    var anomalies = []
    
    for each ngram, count in ngrams:
        var observed_freq = count / total_ngrams
        
        given ngram in expected_freqs:
            var expected_freq = expected_freqs[ngram]
            var ratio = observed_freq / expected_freq
            
            given ratio > 2.0 or ratio < 0.5:
                anomalies.append({
                    'ngram': ngram,
                    'observed': observed_freq,
                    'expected': expected_freq,
                    'ratio': ratio
                })
        given otherwise and count > 1:
            // Ngram not in expected frequencies but occurs multiple times
            anomalies.append({
                'ngram': ngram,
                'observed': observed_freq,
                'expected': 0.0,
                'ratio': float('inf')
            })
    
    // Sort by descending absolute deviation from expected
    anomalies.sort(key=lambda x: abs(x['ratio'] - 1.0), reverse=true)
    
    return anomalies

// Let's analyze our text
print("Analyzing text: " + text)

// Calculate letter frequencies
var freqs = letter_frequency(text)
print("\nLetter frequencies:")
for each letter, freq in sorted(freqs.items()):
    print(f"  {letter}: {freq:.4f}")

// Calculate entropy
var entropy = calculate_entropy(text)
print(f"\nText entropy: {entropy:.4f} bits")

// Find visual patterns
var patterns = detect_visual_patterns(text)
print("\nRecurring visual patterns (by shape class):")
for each pattern, examples in patterns.items():
    print(f"  Pattern {pattern}: {examples}")

// Analyze visual rhythm 
var rhythm = visual_rhythm(text)
print(f"\nVisual rhythm analysis (first 10 points):")
print(f"  {rhythm[:10]}")

// Generate orthographic density map
var density = orthographic_density(text, 20)
print("\nOrthographic density map:")
for each row in density:
    var line = ""
    for each value in row:
        // Convert density to character
        given value < 0.2:
            line = line + " "
        given value < 0.4:
            line = line + "."
        given value < 0.6:
            line = line + "+"
        given value < 0.8:
            line = line + "#"
        given otherwise:
            line = line + "@"
    print(f"  {line}")

// Find unusual letter combinations
var unusual = unusual_combinations(text)
print("\nUnusual letter combinations:")
for i in range(min(5, len(unusual))):
    var item = unusual[i]
    print(f"  {item['ngram']}: observed={item['observed']:.4f}, expected={item['expected']:.4f}, ratio={item['ratio']:.2f}")

// Mathematical operations on patterns
// Division: Split text into visual units by shape class
var text_parts = text / "visual_class"
print("\nText divided by visual classes:")
for each part in text_parts[:5]:
    print(f"  {part}")

// Multiplication: Combine text based on visual similarity
var similar_text = "The quick brown fox" * "jumps over the lazy dog"
print(f"\nVisually combined text: {similar_text}")

// Subtraction: Remove common patterns
var uncommon_text = text - "the"
print(f"\nText with 'the' removed: {uncommon_text}")

// Using propositions and motions
proposition VisualAnalysis:
    motion LetterDistribution("Letter distribution is relatively balanced")
    motion VisualRhythm("Text has a flowing rhythm with good variation")
    motion UnusualPatterns("Text contains pangrams with unusual letter combinations")
    
    within text:
        // Assess entropy relative to English averages (typically 4.0-4.5 bits)
        given entropy < 4.0:
            print("Text has lower than average information density")
        given entropy > 4.5:
            print("Text has higher than average information density")
        given otherwise:
            print("Text has typical information density for English") 